<!DOCTYPE html>
<html lang="en">
  <head>
    <meta http-equiv="x-ua-compatible" content="ie=edge" />
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, viewport-fit=cover"
    />

    <style>
     :root {
       --accent-color: #05a081;
       --accent-color-light: #82d0c0;
     }
    </style>

    <meta name="theme-color" content="#05a081" />

    
    <link rel="alternate" type="application/atom+xml" title="RSS" href="https://wtfleming.github.io/atom.xml">
    

    
    
    
    
    
    
    
    
    
    <link rel="icon" href="https:&#x2F;&#x2F;wtfleming.github.io&#x2F;processed_images&#x2F;icon.b722df128754d46d.png" />

    <link rel="apple-touch-icon" sizes="48x48" href="https:&#x2F;&#x2F;wtfleming.github.io&#x2F;processed_images&#x2F;icon.b722df128754d46d.png" />
    <link rel="apple-touch-icon" sizes="72x72" href="https:&#x2F;&#x2F;wtfleming.github.io&#x2F;processed_images&#x2F;icon.6cc6de892c65b543.png" />
    <link rel="apple-touch-icon" sizes="96x96" href="https:&#x2F;&#x2F;wtfleming.github.io&#x2F;processed_images&#x2F;icon.05bb94ecb36c25eb.png" />
    <link rel="apple-touch-icon" sizes="144x144" href="https:&#x2F;&#x2F;wtfleming.github.io&#x2F;processed_images&#x2F;icon.f51b5e0bcc4516db.png" />
    <link rel="apple-touch-icon" sizes="192x192" href="https:&#x2F;&#x2F;wtfleming.github.io&#x2F;processed_images&#x2F;icon.eae6a2274aff6419.png" />
    <link rel="apple-touch-icon" sizes="256x256" href="https:&#x2F;&#x2F;wtfleming.github.io&#x2F;processed_images&#x2F;icon.2e54fa9ad4d11bdb.png" />
    <link rel="apple-touch-icon" sizes="384x384" href="https:&#x2F;&#x2F;wtfleming.github.io&#x2F;processed_images&#x2F;icon.809ea1a0e3c3f3e0.png" />
    <link rel="apple-touch-icon" sizes="512x512" href="https:&#x2F;&#x2F;wtfleming.github.io&#x2F;processed_images&#x2F;icon.7c64c06f3e2d7a67.png" />
    

    

      <meta property="og:type" content="website">

      <meta name="twitter:card" content="summary">

      

      

      
      
      <meta name="description" content="" />
      <meta name="twitter:description" content="">
      
      

      
      <meta name="twitter:title" content="MNIST Image Classification using Deep Learning and Keras">
      

      
      <link rel="prerender" href="&#x2F;about&#x2F;" />
      
      <link rel="prerender" href="&#x2F;blog&#x2F;" />
      


      
      <link rel="prefetch" href="https:&#x2F;&#x2F;wtfleming.github.io&#x2F;processed_images&#x2F;icon.9401710308142458.png" />

    <title>
      
        
          MNIST Image Classification using Deep Learning and Keras
        
      
    </title>

    
    
      <link rel="stylesheet" href="https://wtfleming.github.io/main.css">
    
    
  

  

  
    <link rel="prerender"  href="https://wtfleming.github.io/tags/keras/">
  
    <link rel="prerender"  href="https://wtfleming.github.io/tags/machine-learning/">
  

  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "NewsArticle",
      "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://google.com/article"
      },
      "headline": "MNIST Image Classification using Deep Learning and Keras",
      "image": [],
      "datePublished": "2019-04-21T00:00:00+00:00",
      "dateModified": "2019-04-21T00:00:00+00:00"
    }
  </script>

  <script type="application/ld+json">
    {
      "@context": "https://schema.org",
      "@type": "BreadcrumbList",
      "itemListElement": [
        

        
        {
          
          "@type": "ListItem",
          "position": 1,
          "name": "Will&#x27;s Software Journal",
          "item": "https://wtfleming.github.io/"
        },
        
        {
          
          "@type": "ListItem",
          "position": 2,
          "name": "",
          "item": "https://wtfleming.github.io/blog/"
        },
        
        {
          "@type": "ListItem",
          "position": 3,
          "name": "MNIST Image Classification using Deep Learning and Keras",
          "item": "https://wtfleming.github.io/blog/keras-mnist/"
        }
      ]
    }
  </script>

  </head>
  <body>
    
    <header>
      
        <a class="profile-icon" href="/">
          <img src="https:&#x2F;&#x2F;wtfleming.github.io&#x2F;processed_images&#x2F;icon.9401710308142458.png" alt="profile picture">
        </a>
        <nav>
          
            <a href="&#x2F;about&#x2F;">About</a>
          
            <a href="&#x2F;blog&#x2F;">Blog</a>
          
        </nav>
      </header>
    
    <main>
    
  <div class="post-title">
    <h1>MNIST Image Classification using Deep Learning and Keras</h1>
    <small>
      April 21, 2019
      
        - 
        <span class="tags">
          
            <a href="https://wtfleming.github.io/tags/keras/">keras</a>
          
            <a href="https://wtfleming.github.io/tags/machine-learning/">machine learning</a>
          
        </span>
      
    </small>
  </div>

  <div>
    <p>In this post we'll use Keras to build the hello world of machine learning, classify a number in an image from the <a href="http://yann.lecun.com/exdb/mnist/index.html">MNIST</a> database of handwritten digits, and achieve ~99% classification accuracy using a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural network</a>.</p>
<p>Much of this is inspired by the book <a href="https://www.manning.com/books/deep-learning-with-python">Deep Learning with Python</a> by Fran√ßois Chollet. I highly recommend reading the book if you would like to dig deeper or learn more.</p>
<p>If you would like to follow along, the code is also available in a <a href="https://github.com/wtfleming/jupyter-notebooks-public/blob/master/mnist-keras.ipynb">jupyter notebook here</a>.</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#b48ead;">from </span><span>keras </span><span style="color:#b48ead;">import </span><span>models, layers
</span><span style="color:#b48ead;">from </span><span>keras.datasets </span><span style="color:#b48ead;">import </span><span>mnist
</span><span style="color:#b48ead;">from </span><span>keras.utils </span><span style="color:#b48ead;">import </span><span>to_categorical
</span><span style="color:#b48ead;">import </span><span>matplotlib.pyplot </span><span style="color:#b48ead;">as </span><span>plt
</span><span style="color:#b48ead;">import </span><span>numpy </span><span style="color:#b48ead;">as </span><span>np
</span></code></pre>
<p>Since working with the MNIST digits is so common, Keras provides a function to load the data. You can see a full <a href="https://keras.io/datasets/">list of datasets</a> Keras has packaged up.</p>
<p>Let's load the data:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span>(train_images, train_labels), (test_images, test_labels) = mnist.</span><span style="color:#bf616a;">load_data</span><span>()
</span></code></pre>
<p>The training set consists of 60,000 28x28 pixel images, and the test set 10,000.</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span>train_images.shape, test_images.shape
</span></code></pre>
<pre style="background-color:#2b303b;color:#c0c5ce;"><code><span>((60000, 28, 28), (10000, 28, 28))
</span></code></pre>
<p>Lets look at the first ten training images. They are each 28x28 grayscale images with one color value between 0 and 255.</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#bf616a;">_</span><span>, ax = plt.</span><span style="color:#bf616a;">subplots</span><span>(</span><span style="color:#d08770;">1</span><span>, </span><span style="color:#d08770;">10</span><span>, </span><span style="color:#bf616a;">figsize</span><span>=(</span><span style="color:#d08770;">10</span><span>,</span><span style="color:#d08770;">10</span><span>))
</span><span>
</span><span style="color:#b48ead;">for </span><span>i </span><span style="color:#b48ead;">in </span><span style="color:#96b5b4;">range</span><span>(</span><span style="color:#d08770;">0</span><span>, </span><span style="color:#d08770;">10</span><span>):
</span><span>    ax[i].</span><span style="color:#bf616a;">axis</span><span>(&#39;</span><span style="color:#a3be8c;">off</span><span>&#39;)
</span><span>    ax[i].</span><span style="color:#bf616a;">imshow</span><span>(train_images[i], </span><span style="color:#bf616a;">cmap</span><span>=plt.cm.binary)
</span></code></pre>
<p>![mnistDigits]({{ site.url }}images/mnist-keras/mnist-example-images.png)</p>
<p>And the labels representing which class the image represents.</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span>train_labels[</span><span style="color:#d08770;">0</span><span>:</span><span style="color:#d08770;">10</span><span>]
</span></code></pre>
<pre style="background-color:#2b303b;color:#c0c5ce;"><code><span>array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)
</span></code></pre>
<h2 id="build-the-neural-network">Build the neural network</h2>
<p>Now build the neural network. We'll be using a number of convolutional layers. Note that we only have to specify the input shape in the first layer. The last layer provides the output. It has 10 units (one for each digit 0 to 9) and uses a softmax activation to map the output of a network to a probability distribution over the predicted output classes.</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span>model = models.</span><span style="color:#bf616a;">Sequential</span><span>()
</span><span>model.</span><span style="color:#bf616a;">add</span><span>(layers.</span><span style="color:#bf616a;">Conv2D</span><span>(</span><span style="color:#d08770;">32</span><span>, (</span><span style="color:#d08770;">3</span><span>, </span><span style="color:#d08770;">3</span><span>), </span><span style="color:#bf616a;">activation</span><span>=&#39;</span><span style="color:#a3be8c;">relu</span><span>&#39;, </span><span style="color:#bf616a;">input_shape</span><span>=(</span><span style="color:#d08770;">28</span><span>, </span><span style="color:#d08770;">28</span><span>, </span><span style="color:#d08770;">1</span><span>)))
</span><span>model.</span><span style="color:#bf616a;">add</span><span>(layers.</span><span style="color:#bf616a;">MaxPooling2D</span><span>((</span><span style="color:#d08770;">2</span><span>, </span><span style="color:#d08770;">2</span><span>)))
</span><span>model.</span><span style="color:#bf616a;">add</span><span>(layers.</span><span style="color:#bf616a;">Conv2D</span><span>(</span><span style="color:#d08770;">64</span><span>, (</span><span style="color:#d08770;">3</span><span>, </span><span style="color:#d08770;">3</span><span>), </span><span style="color:#bf616a;">activation</span><span>=&#39;</span><span style="color:#a3be8c;">relu</span><span>&#39;))
</span><span>model.</span><span style="color:#bf616a;">add</span><span>(layers.</span><span style="color:#bf616a;">MaxPooling2D</span><span>((</span><span style="color:#d08770;">2</span><span>, </span><span style="color:#d08770;">2</span><span>)))
</span><span>model.</span><span style="color:#bf616a;">add</span><span>(layers.</span><span style="color:#bf616a;">Conv2D</span><span>(</span><span style="color:#d08770;">64</span><span>, (</span><span style="color:#d08770;">3</span><span>, </span><span style="color:#d08770;">3</span><span>), </span><span style="color:#bf616a;">activation</span><span>=&#39;</span><span style="color:#a3be8c;">relu</span><span>&#39;))
</span><span>model.</span><span style="color:#bf616a;">add</span><span>(layers.</span><span style="color:#bf616a;">Flatten</span><span>())
</span><span>model.</span><span style="color:#bf616a;">add</span><span>(layers.</span><span style="color:#bf616a;">Dense</span><span>(</span><span style="color:#d08770;">64</span><span>, </span><span style="color:#bf616a;">activation</span><span>=&#39;</span><span style="color:#a3be8c;">relu</span><span>&#39;))
</span><span>model.</span><span style="color:#bf616a;">add</span><span>(layers.</span><span style="color:#bf616a;">Dense</span><span>(</span><span style="color:#d08770;">10</span><span>, </span><span style="color:#bf616a;">activation</span><span>=&#39;</span><span style="color:#a3be8c;">softmax</span><span>&#39;))
</span><span>
</span><span>model.</span><span style="color:#bf616a;">compile</span><span>(</span><span style="color:#bf616a;">optimizer</span><span>=&#39;</span><span style="color:#a3be8c;">rmsprop</span><span>&#39;, </span><span style="color:#bf616a;">loss</span><span>=&#39;</span><span style="color:#a3be8c;">categorical_crossentropy</span><span>&#39;, </span><span style="color:#bf616a;">metrics</span><span>=[&#39;</span><span style="color:#a3be8c;">accuracy</span><span>&#39;])
</span></code></pre>
<p>One way to see what the network looks like is to use the summary() function:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span>model.</span><span style="color:#bf616a;">summary</span><span>()
</span></code></pre>
<pre style="background-color:#2b303b;color:#c0c5ce;"><code><span>_________________________________________________________________
</span><span>Layer (type)                 Output Shape              Param #   
</span><span>=================================================================
</span><span>conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       
</span><span>_________________________________________________________________
</span><span>max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         
</span><span>_________________________________________________________________
</span><span>conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     
</span><span>_________________________________________________________________
</span><span>max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         
</span><span>_________________________________________________________________
</span><span>conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     
</span><span>_________________________________________________________________
</span><span>flatten_1 (Flatten)          (None, 576)               0         
</span><span>_________________________________________________________________
</span><span>dense_1 (Dense)              (None, 64)                36928     
</span><span>_________________________________________________________________
</span><span>dense_2 (Dense)              (None, 10)                650       
</span><span>=================================================================
</span><span>Total params: 93,322
</span><span>Trainable params: 93,322
</span><span>Non-trainable params: 0
</span><span>_________________________________________________________________
</span></code></pre>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span>(train_images, train_labels), (test_images, test_labels) = mnist.</span><span style="color:#bf616a;">load_data</span><span>()
</span></code></pre>
<p>We need to do some preprocessing of the images. We'll also use the first 50,000 training images for training, and the remaining 10,000 training examples for cross validation.</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span>train_images = train_images.</span><span style="color:#bf616a;">reshape</span><span>((</span><span style="color:#d08770;">60000</span><span>, </span><span style="color:#d08770;">28</span><span>, </span><span style="color:#d08770;">28</span><span>, </span><span style="color:#d08770;">1</span><span>))
</span><span>train_images= train_images.</span><span style="color:#bf616a;">astype</span><span>(&#39;</span><span style="color:#a3be8c;">float32</span><span>&#39;) / </span><span style="color:#d08770;">255 </span><span style="color:#65737e;"># rescale pixel values from range [0, 255] to [0, 1]
</span><span>
</span><span>test_images = test_images.</span><span style="color:#bf616a;">reshape</span><span>((</span><span style="color:#d08770;">10000</span><span>, </span><span style="color:#d08770;">28</span><span>, </span><span style="color:#d08770;">28</span><span>, </span><span style="color:#d08770;">1</span><span>))
</span><span>test_images= test_images.</span><span style="color:#bf616a;">astype</span><span>(&#39;</span><span style="color:#a3be8c;">float32</span><span>&#39;) / </span><span style="color:#d08770;">255
</span><span>
</span><span>train_labels = </span><span style="color:#bf616a;">to_categorical</span><span>(train_labels)
</span><span>test_labels = </span><span style="color:#bf616a;">to_categorical</span><span>(test_labels)
</span><span>
</span><span>validation_images = train_images[</span><span style="color:#d08770;">50000</span><span>:]
</span><span>validation_labels = train_labels[</span><span style="color:#d08770;">50000</span><span>:]
</span><span>
</span><span>train_images = train_images[:</span><span style="color:#d08770;">50000</span><span>]
</span><span>train_labels = train_labels[:</span><span style="color:#d08770;">50000</span><span>]
</span><span>
</span><span>history = model.</span><span style="color:#bf616a;">fit</span><span>(train_images, train_labels, </span><span style="color:#bf616a;">epochs</span><span>=</span><span style="color:#d08770;">5</span><span>, </span><span style="color:#bf616a;">batch_size</span><span>=</span><span style="color:#d08770;">64</span><span>, </span><span style="color:#bf616a;">validation_data</span><span>=(validation_images, validation_labels))
</span></code></pre>
<pre style="background-color:#2b303b;color:#c0c5ce;"><code><span>Train on 50000 samples, validate on 10000 samples
</span><span>Epoch 1/5
</span><span>50000/50000 [==============================] - 20s 391us/step - loss: 0.1959 - acc: 0.9387 - val_loss: 0.0798 - val_acc: 0.9760
</span><span>Epoch 2/5
</span><span>50000/50000 [==============================] - 19s 380us/step - loss: 0.0509 - acc: 0.9845 - val_loss: 0.0513 - val_acc: 0.9849
</span><span>Epoch 3/5
</span><span>50000/50000 [==============================] - 19s 382us/step - loss: 0.0343 - acc: 0.9892 - val_loss: 0.0408 - val_acc: 0.9880
</span><span>Epoch 4/5
</span><span>50000/50000 [==============================] - 19s 379us/step - loss: 0.0257 - acc: 0.9918 - val_loss: 0.0448 - val_acc: 0.9874
</span><span>Epoch 5/5
</span><span>50000/50000 [==============================] - 19s 377us/step - loss: 0.0208 - acc: 0.9938 - val_loss: 0.0356 - val_acc: 0.9903
</span></code></pre>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span>test_loss, test_acc = model.</span><span style="color:#bf616a;">evaluate</span><span>(test_images, test_labels)
</span><span style="color:#96b5b4;">print</span><span>(&#39;</span><span style="color:#a3be8c;">Accuracy:</span><span>&#39;, test_acc)
</span><span style="color:#96b5b4;">print</span><span>(&#39;</span><span style="color:#a3be8c;">Loss: </span><span>&#39;, test_loss)
</span></code></pre>
<pre style="background-color:#2b303b;color:#c0c5ce;"><code><span>10000/10000 [==============================] - 1s 122us/step
</span><span>Accuracy: 0.992
</span><span>Loss:  0.027386048025220953
</span></code></pre>
<p>Looks pretty good we're seeing ~99% accuracy on the test set.</p>
<h2 id="visualize-training">Visualize training</h2>
<p>Now lets create a function that lets us graph the accuracy and loss values during training.</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#b48ead;">def </span><span style="color:#8fa1b3;">plot_accuracy_and_loss</span><span>(</span><span style="color:#bf616a;">history</span><span>):
</span><span>    acc = history.history[&#39;</span><span style="color:#a3be8c;">acc</span><span>&#39;]
</span><span>    val_acc = history.history[&#39;</span><span style="color:#a3be8c;">val_acc</span><span>&#39;]
</span><span>    loss = history.history[&#39;</span><span style="color:#a3be8c;">loss</span><span>&#39;]
</span><span>    val_loss = history.history[&#39;</span><span style="color:#a3be8c;">val_loss</span><span>&#39;]
</span><span>
</span><span>    epochs = </span><span style="color:#96b5b4;">range</span><span>(</span><span style="color:#d08770;">1</span><span>, </span><span style="color:#96b5b4;">len</span><span>(acc) + </span><span style="color:#d08770;">1</span><span>)
</span><span>
</span><span>    plt.</span><span style="color:#bf616a;">plot</span><span>(epochs, acc, &#39;</span><span style="color:#a3be8c;">bo</span><span>&#39;, </span><span style="color:#bf616a;">label</span><span>=&#39;</span><span style="color:#a3be8c;">Training acc</span><span>&#39;)
</span><span>    plt.</span><span style="color:#bf616a;">plot</span><span>(epochs, val_acc, &#39;</span><span style="color:#a3be8c;">b</span><span>&#39;, </span><span style="color:#bf616a;">label</span><span>=&#39;</span><span style="color:#a3be8c;">Validation acc</span><span>&#39;)
</span><span>    plt.</span><span style="color:#bf616a;">title</span><span>(&#39;</span><span style="color:#a3be8c;">Training and validation accuracy</span><span>&#39;)
</span><span>    plt.</span><span style="color:#bf616a;">legend</span><span>()
</span><span>    plt.</span><span style="color:#bf616a;">show</span><span>()
</span><span>
</span><span>    plt.</span><span style="color:#bf616a;">plot</span><span>(epochs, loss, &#39;</span><span style="color:#a3be8c;">bo</span><span>&#39;, </span><span style="color:#bf616a;">label</span><span>=&#39;</span><span style="color:#a3be8c;">Training loss</span><span>&#39;)
</span><span>    plt.</span><span style="color:#bf616a;">plot</span><span>(epochs, val_loss, &#39;</span><span style="color:#a3be8c;">b</span><span>&#39;, </span><span style="color:#bf616a;">label</span><span>=&#39;</span><span style="color:#a3be8c;">Validation loss</span><span>&#39;)
</span><span>    plt.</span><span style="color:#bf616a;">title</span><span>(&#39;</span><span style="color:#a3be8c;">Training and validation loss</span><span>&#39;)
</span><span>    plt.</span><span style="color:#bf616a;">legend</span><span>()
</span><span>    plt.</span><span style="color:#bf616a;">show</span><span>()
</span><span>
</span><span style="color:#bf616a;">plot_accuracy_and_loss</span><span>(history)
</span></code></pre>
<p>![plot-accuracy-loss]({{ site.url }}images/mnist-keras/plot-accuracy-loss.png)</p>
<p>The above looks pretty good, we appear to be starting to overfit the data as we get further in, but training and validation sets are pretty close to each other.</p>
<p>Now lets look at a prediction, first we'll generate predictions for the test set.</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span>preds = model.</span><span style="color:#bf616a;">predict</span><span>(test_images)
</span></code></pre>
<p>We'll use the network to try to figure out what the first digit in the test set is. If we manually look, it appears to be a 7.</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#65737e;"># reload the test images so it will be in a format imshow() will understand
</span><span>(</span><span style="color:#bf616a;">_</span><span>, </span><span style="color:#bf616a;">_</span><span>), (test_images, </span><span style="color:#bf616a;">_</span><span>) = mnist.</span><span style="color:#bf616a;">load_data</span><span>()
</span><span>
</span><span>plt.</span><span style="color:#bf616a;">imshow</span><span>(test_images[</span><span style="color:#d08770;">0</span><span>], </span><span style="color:#bf616a;">cmap</span><span>=plt.cm.binary)
</span></code></pre>
<p>![test-prediction]({{ site.url }}images/mnist-keras/test-prediction.png)</p>
<p>Since the output of the network was a layer with 10 units and a softmax activation, we will get an array of length 10 with a prediction for each potential number. Here you can see that the network is 99.9% certain it is a seven.</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span style="color:#96b5b4;">print</span><span>(preds[</span><span style="color:#d08770;">0</span><span>])
</span></code></pre>
<pre style="background-color:#2b303b;color:#c0c5ce;"><code><span>[2.6081236e-12 1.8943378e-09 1.0174886e-08 6.8640638e-08 2.3309353e-11
</span><span> 1.9539477e-10 7.4824168e-19 9.9999988e-01 4.3342949e-10 8.6599723e-09]
</span></code></pre>
<p>We can also find the class with the highest prediction score with a numpy function:</p>
<pre data-lang="python" style="background-color:#2b303b;color:#c0c5ce;" class="language-python "><code class="language-python" data-lang="python"><span>np.</span><span style="color:#bf616a;">argmax</span><span>(preds[</span><span style="color:#d08770;">0</span><span>])
</span></code></pre>
<pre style="background-color:#2b303b;color:#c0c5ce;"><code><span>7
</span></code></pre>
<p>The next step would be to retrain the model with all 60,000 training examples (remember that in the model above we trained on 50,000 examples and validated on the remaining 10,000). I'll leave that as an exercise to the reader.</p>

  </div>

  <hr class="footer-rule" />

  

  <div class="related-container">

    

    

  </div>


    </main>
  </body>
</html>
